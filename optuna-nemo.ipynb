{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import nemo\n",
    "import nemo.collections.nlp as nemo_nlp\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "import torch.multiprocessing as mp\n",
    "from nemo.collections.nlp.models.language_modeling.megatron_gpt_model import MegatronGPTModel\n",
    "from nemo.collections.nlp.parts.megatron_trainer_builder import MegatronTrainerBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf.omegaconf import OmegaConf, open_dict\n",
    "from nemo.utils import logging\n",
    "from nemo.utils.exp_manager import exp_manager\n",
    "from nemo.core.config import hydra_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.set_start_method(\"spawn\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    with initialize(version_base=None, config_path=\"config\"):\n",
    "        cfg = compose(config_name=\"llama2_7b_optuna.yaml\")\n",
    "    print(f'\\n{OmegaConf.to_yaml(cfg)}')\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(cfg, trainer):\n",
    "    logging.info(\"\\n\\n************** Experiment configuration ***********\")\n",
    "    logging.info(f'\\n{OmegaConf.to_yaml(cfg)}')\n",
    "    \n",
    "    # Continual training\n",
    "    if cfg.model.get(\"restore_from_path\") is not None:\n",
    "        # Option 1: Restore only the model weights from a .nemo file\n",
    "        logging.info(f\"Continual training: loading weights from {cfg.model.restore_from_path}\")\n",
    "        model = MegatronGPTModel.restore_from(\n",
    "            restore_path=cfg.model.restore_from_path,\n",
    "            override_config_path=cfg.model,\n",
    "            trainer=trainer,\n",
    "            save_restore_connector=NLPSaveRestoreConnector(),\n",
    "        )\n",
    "    elif cfg.model.get(\"restore_from_ckpt\") is not None:\n",
    "        # Option 2: Restore both model weights and optimizer states from a PTL checkpoint\n",
    "        logging.info(f\"Continual training: loading weights and optimizer states from {cfg.model.restore_from_ckpt}\")\n",
    "        trainer.ckpt_path = Path(cfg.model.restore_from_ckpt)\n",
    "        model = MegatronGPTModel(cfg.model, trainer)\n",
    "    else:\n",
    "        # Start new pretraining or resume from a checkpoint if it exists\n",
    "        model = MegatronGPTModel(cfg.model, trainer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    cfg = get_config()\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-2, log=True)\n",
    "    warmup_ratio = trial.suggest_float(\"warmup_ratio\", 0.0, 0.2)\n",
    "\n",
    "    \n",
    "\n",
    "    trainer = MegatronTrainerBuilder(cfg).create_trainer()\n",
    "    exp_manager(trainer, cfg.exp_manager)\n",
    "\n",
    "    # Load the pre-trained Llama 2 model\n",
    "    model = initialize_model(cfg, trainer)\n",
    "\n",
    "    # Configure the model with suggested hyperparameters\n",
    "    model.cfg.optim.lr = learning_rate\n",
    "    model.cfg.optim.weight_decay = weight_decay\n",
    "    model.cfg.optim.sched.warmup_ratio = warmup_ratio\n",
    "\n",
    "\n",
    "    # Fine-tune the model\n",
    "    trainer.fit(model)\n",
    "\n",
    "    # Return the validation loss as the objective value\n",
    "    return trainer.callback_metrics['val_loss'].item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the hyperparameters\n",
    "study.optimize(objective, n_trials=3, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters and corresponding validation loss\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best validation loss:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_config()\n",
    "\n",
    "# setting custom values\n",
    "cfg.trainer.max_epochs = 10\n",
    "cfg.trainer.devices = 1\n",
    "cfg.trainer.precision = 16\n",
    "cfg.trainer.accelerator = \"gpu\"\n",
    "cfg.trainer.log_every_n_steps = 10\n",
    "cfg.trainer.val_check_interval = 0.5\n",
    "\n",
    "\n",
    "best_trainer = MegatronTrainerBuilder(cfg).create_trainer()\n",
    "\n",
    "# best_trainer = pl.Trainer(\n",
    "#     max_epochs=10,\n",
    "#     gpus=1,\n",
    "#     precision=16,\n",
    "#     amp_level='O2',\n",
    "#     accelerator=\"gpu\",\n",
    "#     strategy=\"ddp\",\n",
    "#     log_every_n_steps=10,\n",
    "#     val_check_interval=0.5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fine-tune the model with the best hyperparameters\n",
    "best_model = initialize_model(cfg, best_trainer)\n",
    "best_model.cfg.optim.lr = study.best_params[\"learning_rate\"]\n",
    "best_model.cfg.optim.weight_decay = study.best_params[\"weight_decay\"]\n",
    "best_model.cfg.optim.sched.warmup_ratio = study.best_params[\"warmup_ratio\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg.exp_manager.exp_dir=\"best_model_experiment\"\n",
    "cfg.exp_manager.create_wandb_logger=False\n",
    "\n",
    "best_trainer.logger=None\n",
    "cfg.trainer.max_steps=\"null\"\n",
    "cfg.trainer.max_epochs=1\n",
    "exp_manager(\n",
    "    best_trainer,\n",
    "    cfg.exp_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trainer.fit(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the fine-tuned model\n",
    "best_model.save_to(\"llama2-7b-finetuned-optuna.nemo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
